{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaTTQ6iSRVZx"
   },
   "source": [
    "# Tensorflow 2 Object Detection: Train model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXQCIqYmB-pp"
   },
   "source": [
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
    "  </a>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28222,
     "status": "ok",
     "timestamp": 1612975037489,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "xJu28v9iHsce",
    "outputId": "5f7c6969-1f29-43d6-f222-111bd03d1614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "# Connect your google drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 70131,
     "status": "ok",
     "timestamp": 1612975112052,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "fTBYWlnKSD78",
    "outputId": "3f87d882-be56-407b-f95b-1848b586068c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/ae/0b08f53498417914f2274cc3b5576d2b83179b0cbb209457d0fde0152174/tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4MB 51kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 52.0MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.32.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1MB 9.7MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.36.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (53.0.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, numpy, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed numpy-1.18.5 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -U --pre tensorflow==\"2.3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76546,
     "status": "ok",
     "timestamp": 1612975121558,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "Kpha2-F_SGBj",
    "outputId": "4edfc552-0714-452d-934b-55278a003adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 2407, done.\u001b[K\n",
      "remote: Counting objects: 100% (2407/2407), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2011/2011), done.\u001b[K\n",
      "remote: Total 2407 (delta 573), reused 1381 (delta 369), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (2407/2407), 30.78 MiB | 36.82 MiB/s, done.\n",
      "Resolving deltas: 100% (573/573), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88373,
     "status": "ok",
     "timestamp": 1612975209946,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "rmr2UdV_SHuc",
    "outputId": "6737cb7f-34f6-4acb-cd29-5d0749f2adeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/models/research\n",
      "Collecting avro-python3\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/84/ef37f882a7d93674d6fe1aa6e99f18cf2f34e9b775952f3d85587c11c92e/avro-python3-1.10.1.tar.gz\n",
      "Collecting apache-beam\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/f8/afcd9a457d92bd7858df5ece8f8ecae7d7387fbbb6e3438c6cb495278743/apache_beam-2.27.0-cp36-cp36m-manylinux2010_x86_64.whl (9.0MB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n",
      "Collecting tf-slim\n",
      "  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n",
      "Collecting lvis\n",
      "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.5)\n",
      "Collecting tf-models-official\n",
      "  Downloading https://files.pythonhosted.org/packages/57/4a/23a08f8fd2747867ee223612e219eeb0d11c36116601d99b55ef3c72e707/tf_models_official-2.4.0-py2.py3-none-any.whl (1.1MB)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
      "Collecting pyarrow<3.0.0,>=0.15.1\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
      "Collecting mock<3.0.0,>=1.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
      "Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/20/40f9b8df7691ccd5bb452e789507708804df55b7fd4041936c7c84d2ebea/fastavro-1.3.1-cp36-cp36m-manylinux2014_x86_64.whl (2.2MB)\n",
      "Collecting future<1.0.0,>=0.18.2\n",
      "  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz (41kB)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.3)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (53.0.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
      "Collecting tensorflow>=2.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/14/3724e7316a065b79174b10e34471e21ebb6896efbb82f689651584e6f5da/tensorflow-2.4.1-cp36-cp36m-manylinux2010_x86_64.whl (394.3MB)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Collecting seqeval\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/5b/bc0b5ab38247bba158504a410112b6c03f153c652734ece1849749e5f518/PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading https://files.pythonhosted.org/packages/96/fc/4da675cc522a749ebbcf85c5a63fba844b2d44c87e6f24e3fdb147df3270/opencv_python_headless-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (37.6MB)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.10)\n",
      "Collecting sentencepiece\n",
      "  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
      "Collecting pbr>=0.11\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.5)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.27.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.25.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Building wheels for collected packages: object-detection, avro-python3, dill, future, hdfs, seqeval, py-cpuinfo\n",
      "  Building wheel for object-detection (setup.py): started\n",
      "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1618454 sha256=10dc5162d2f01b47dce086f12e1e06ed9487bf1bb861e0cb77d426d45d68b53f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ajkp8fi7/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
      "  Building wheel for avro-python3 (setup.py): started\n",
      "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.10.1-cp36-none-any.whl size=43734 sha256=6d9ea1dbf33e0723b8dbf9048fe1ebc031ae3eb8cd5e4697d5f46e5146e20646\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/fe/90/20d6d6d97223d80d20cb390be636619c536edab5658c12bdba\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78533 sha256=5cb05a1965fde8a21f304c0d56effc60d01066602c0d704e2124bb4a19c19786\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=3a51600973ddc0063650b891f39e5dca170dbff1ceecfa2571e9abb6f8dd22af\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "  Building wheel for hdfs (setup.py): started\n",
      "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
      "  Created wheel for hdfs: filename=hdfs-2.5.8-cp36-none-any.whl size=33213 sha256=aa573f877ffcda433bc3667075a45960c93a921d2e66c132bb5f6772c1bdb0ee\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=5fe3a08cf5ceaef650c11bd07b971e85be79cc5cd53dd7de43d50200af6bd563\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "  Building wheel for py-cpuinfo (setup.py): started\n",
      "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20072 sha256=959842d65176022229191ededebf79c07b0461749663dca0dec078c038e7d6d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
      "Successfully built object-detection avro-python3 dill future hdfs seqeval py-cpuinfo\n",
      "Installing collected packages: avro-python3, requests, dill, pyarrow, pbr, mock, fastavro, future, hdfs, apache-beam, tf-slim, lvis, tensorflow-model-optimization, tensorflow-estimator, tensorflow, seqeval, py-cpuinfo, pyyaml, opencv-python-headless, sentencepiece, tf-models-official, object-detection\n",
      "  Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Found existing installation: dill 0.3.3\n",
      "    Uninstalling dill-0.3.3:\n",
      "      Successfully uninstalled dill-0.3.3\n",
      "  Found existing installation: pyarrow 0.14.1\n",
      "    Uninstalling pyarrow-0.14.1:\n",
      "      Successfully uninstalled pyarrow-0.14.1\n",
      "  Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "  Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Found existing installation: tensorflow 2.3.0\n",
      "    Uninstalling tensorflow-2.3.0:\n",
      "      Successfully uninstalled tensorflow-2.3.0\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed apache-beam-2.27.0 avro-python3-1.10.1 dill-0.3.1.1 fastavro-1.3.1 future-0.18.2 hdfs-2.5.8 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.5.1.48 pbr-5.5.1 py-cpuinfo-7.0.0 pyarrow-2.0.0 pyyaml-5.4.1 requests-2.25.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-2.4.1 tensorflow-estimator-2.4.0 tensorflow-model-optimization-0.5.0 tf-models-official-2.4.0 tf-slim-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\n",
      "ERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\n",
      "ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\n",
      "ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
      "ERROR: apache-beam 2.27.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Install the Object Detection API\n",
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124644,
     "status": "ok",
     "timestamp": 1612975246230,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "XzXxTBXHSNqA",
    "outputId": "3155ea39-68c8-4008-dff2-a5d8a1e2aa3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-10 16:40:10.427342: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:40:10.427387: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Running tests under Python 3.6.9: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
      "2021-02-10 16:40:16.876780: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-10 16:40:16.878631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-02-10 16:40:16.929636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-02-10 16:40:16.930270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-02-10 16:40:16.930408: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:40:16.930570: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:40:16.930711: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:40:17.011624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-02-10 16:40:17.068056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-02-10 16:40:17.315044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-02-10 16:40:17.315339: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:40:17.315475: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:40:17.315495: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-02-10 16:40:17.315832: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-10 16:40:17.316003: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-10 16:40:17.316046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-02-10 16:40:17.316059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 3.6s\n",
      "I0210 16:40:20.280946 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 3.6s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0210 16:40:20.282006 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "I0210 16:40:20.324093 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "I0210 16:40:20.343648 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I0210 16:40:20.364796 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
      "I0210 16:40:20.505477 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
      "I0210 16:40:20.640032 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
      "I0210 16:40:20.778797 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.15s\n",
      "I0210 16:40:20.932869 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.15s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
      "I0210 16:40:21.083327 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "I0210 16:40:21.131143 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0210 16:40:21.560759 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0210 16:40:21.560927 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n",
      "I0210 16:40:21.561001 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n",
      "I0210 16:40:21.566064 140409873176448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0210 16:40:21.584363 140409873176448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0210 16:40:21.584514 140409873176448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0210 16:40:21.639411 140409873176448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0210 16:40:21.639553 140409873176448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0210 16:40:21.775405 140409873176448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0210 16:40:21.775591 140409873176448 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0210 16:40:21.935643 140409873176448 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0210 16:40:21.935813 140409873176448 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0210 16:40:22.147667 140409873176448 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0210 16:40:22.147845 140409873176448 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0210 16:40:22.370680 140409873176448 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0210 16:40:22.370856 140409873176448 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0210 16:40:22.705775 140409873176448 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0210 16:40:22.705956 140409873176448 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0210 16:40:22.785134 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0210 16:40:22.827594 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0210 16:40:22.905856 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0210 16:40:22.906029 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n",
      "I0210 16:40:22.906123 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n",
      "I0210 16:40:22.910168 140409873176448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0210 16:40:22.924754 140409873176448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0210 16:40:22.924873 140409873176448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0210 16:40:23.037554 140409873176448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0210 16:40:23.037686 140409873176448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0210 16:40:23.253033 140409873176448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0210 16:40:23.253227 140409873176448 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0210 16:40:23.465843 140409873176448 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0210 16:40:23.466057 140409873176448 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0210 16:40:23.764175 140409873176448 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0210 16:40:23.764365 140409873176448 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0210 16:40:24.067235 140409873176448 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0210 16:40:24.067416 140409873176448 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0210 16:40:24.588274 140409873176448 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0210 16:40:24.588441 140409873176448 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0210 16:40:24.780918 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0210 16:40:24.825940 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0210 16:40:24.907865 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0210 16:40:24.908041 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n",
      "I0210 16:40:24.908137 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n",
      "I0210 16:40:24.912629 140409873176448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0210 16:40:24.927135 140409873176448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0210 16:40:24.927253 140409873176448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0210 16:40:25.042578 140409873176448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0210 16:40:25.042711 140409873176448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0210 16:40:25.261436 140409873176448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0210 16:40:25.261603 140409873176448 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0210 16:40:25.476906 140409873176448 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0210 16:40:25.477096 140409873176448 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0210 16:40:25.774008 140409873176448 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0210 16:40:25.774193 140409873176448 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0210 16:40:26.086754 140409873176448 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0210 16:40:26.086940 140409873176448 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0210 16:40:26.505440 140409873176448 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0210 16:40:26.505625 140409873176448 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0210 16:40:26.703166 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0210 16:40:26.753170 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0210 16:40:26.831353 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0210 16:40:26.831518 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n",
      "I0210 16:40:26.831597 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n",
      "I0210 16:40:26.835684 140409873176448 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0210 16:40:26.849541 140409873176448 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0210 16:40:26.849657 140409873176448 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0210 16:40:26.967685 140409873176448 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0210 16:40:26.967863 140409873176448 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0210 16:40:27.173651 140409873176448 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0210 16:40:27.173820 140409873176448 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0210 16:40:27.387342 140409873176448 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0210 16:40:27.387536 140409873176448 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0210 16:40:27.750669 140409873176448 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0210 16:40:27.750862 140409873176448 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0210 16:40:28.146347 140409873176448 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0210 16:40:28.146519 140409873176448 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0210 16:40:28.855923 140409873176448 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0210 16:40:28.856113 140409873176448 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0210 16:40:29.064640 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0210 16:40:29.111668 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0210 16:40:29.199276 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0210 16:40:29.199452 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n",
      "I0210 16:40:29.199540 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
      "I0210 16:40:29.203804 140409873176448 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0210 16:40:29.218435 140409873176448 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0210 16:40:29.218567 140409873176448 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0210 16:40:29.327733 140409873176448 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0210 16:40:29.327856 140409873176448 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0210 16:40:29.617168 140409873176448 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0210 16:40:29.617347 140409873176448 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0210 16:40:29.915390 140409873176448 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0210 16:40:29.915582 140409873176448 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0210 16:40:30.379984 140409873176448 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0210 16:40:30.380172 140409873176448 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0210 16:40:30.881421 140409873176448 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0210 16:40:30.881620 140409873176448 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0210 16:40:31.669002 140409873176448 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0210 16:40:31.669201 140409873176448 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0210 16:40:31.915724 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0210 16:40:31.970783 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0210 16:40:32.074010 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0210 16:40:32.074236 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n",
      "I0210 16:40:32.074317 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
      "I0210 16:40:32.078638 140409873176448 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0210 16:40:32.093334 140409873176448 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0210 16:40:32.093451 140409873176448 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0210 16:40:32.266200 140409873176448 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0210 16:40:32.266370 140409873176448 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0210 16:40:32.633408 140409873176448 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0210 16:40:32.633591 140409873176448 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0210 16:40:33.185754 140409873176448 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0210 16:40:33.185930 140409873176448 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0210 16:40:33.736429 140409873176448 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0210 16:40:33.736613 140409873176448 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0210 16:40:34.328130 140409873176448 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0210 16:40:34.328305 140409873176448 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0210 16:40:35.250001 140409873176448 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0210 16:40:35.250208 140409873176448 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0210 16:40:35.663965 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0210 16:40:35.729166 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0210 16:40:35.833791 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0210 16:40:35.833966 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
      "I0210 16:40:35.834050 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
      "I0210 16:40:35.838285 140409873176448 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0210 16:40:35.853648 140409873176448 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0210 16:40:35.853762 140409873176448 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0210 16:40:36.041235 140409873176448 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0210 16:40:36.041410 140409873176448 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0210 16:40:36.485883 140409873176448 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0210 16:40:36.486095 140409873176448 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0210 16:40:36.923009 140409873176448 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0210 16:40:36.923203 140409873176448 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0210 16:40:37.704041 140409873176448 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0210 16:40:37.704241 140409873176448 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0210 16:40:38.402216 140409873176448 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0210 16:40:38.402393 140409873176448 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0210 16:40:39.571969 140409873176448 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0210 16:40:39.572201 140409873176448 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0210 16:40:40.046850 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0210 16:40:40.127411 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0210 16:40:40.250022 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0210 16:40:40.250203 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
      "I0210 16:40:40.250278 140409873176448 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
      "I0210 16:40:40.254572 140409873176448 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0210 16:40:40.269424 140409873176448 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0210 16:40:40.269546 140409873176448 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0210 16:40:40.499448 140409873176448 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0210 16:40:40.499666 140409873176448 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0210 16:40:41.006572 140409873176448 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0210 16:40:41.006758 140409873176448 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0210 16:40:41.533858 140409873176448 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0210 16:40:41.534045 140409873176448 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0210 16:40:42.352906 140409873176448 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0210 16:40:42.353119 140409873176448 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0210 16:40:43.429991 140409873176448 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0210 16:40:43.430196 140409873176448 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0210 16:40:44.949249 140409873176448 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0210 16:40:44.949428 140409873176448 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0210 16:40:45.694716 140409873176448 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0210 16:40:45.782866 140409873176448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.79s\n",
      "I0210 16:40:45.920257 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.79s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0210 16:40:45.926690 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0210 16:40:45.928226 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0210 16:40:45.928662 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0210 16:40:45.930066 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0210 16:40:45.931288 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0210 16:40:45.931720 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0210 16:40:45.932659 140409873176448 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 20 tests in 29.256s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "#run model builder test\n",
    "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "3KHDdTY_cm5G",
    "outputId": "737cebbc-8a74-4913-a250-bdad41d58577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-18 15:54:55--  https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/generate_tfrecord.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3382 (3.3K) [text/plain]\n",
      "Saving to: ‘generate_tfrecord.py’\n",
      "\n",
      "\r",
      "generate_tfrecord.p   0%[                    ]       0  --.-KB/s               \r",
      "generate_tfrecord.p 100%[===================>]   3.30K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-07-18 15:54:55 (53.3 MB/s) - ‘generate_tfrecord.py’ saved [3382/3382]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/master/generate_tfrecord.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "hs4KdOs7coyX",
    "outputId": "f0c2068b-a1a2-4d2b-9f90-56f25f85c982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-18 15:55:01.284990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "Successfully created the TFRecords: /content/train.record\n",
      "2020-07-18 15:55:04.972641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "Successfully created the TFRecords: /content/test.record\n"
     ]
    }
   ],
   "source": [
    "!python generate_tfrecord.py --csv_input=content/gdrive/MyDrive/images/train_labels.csv --image_dir=content/gdrive/MyDrive/images/train --output_path=train.record\n",
    "!python generate_tfrecord.py --csv_input=content/gdrive/MyDrive/images/test_labels.csv --image_dir=content/gdrive/MyDrive/images/test --output_path=test.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1612975247114,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "Z_W_8L24c4Sk"
   },
   "outputs": [],
   "source": [
    "train_record_path = '/content/gdrive/MyDrive/imagesV2/train.record'\n",
    "test_record_path = '/content/gdrive/MyDrive/imagesV2/test.record'\n",
    "labelmap_path = '/content/gdrive/MyDrive/imagesV2/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SK79i98YSY8a"
   },
   "source": [
    "## Configuring training\n",
    "\n",
    "Now that the data is ready it's time to create a training configuration. The OD API supports lots of models, each with its own config file. In this notebook I'm making use of EfficientDet, but you can replace it with any model available in the [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1612975247116,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "Axko9Jd0hEI3"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 1\n",
    "num_steps = 8000\n",
    "num_eval_steps = 1000\n",
    "learning_rate_base = 8e-4\n",
    "warmup_learning_rate = .00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6411,
     "status": "ok",
     "timestamp": 1612975252706,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "8RNI68K_dyzX",
    "outputId": "204271e5-f05d-45d3-a8de-94e50366fa1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-10 16:40:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.253.62.128, 2607:f8b0:4004:c07::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.253.62.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 211996178 (202M) [application/x-tar]\n",
      "Saving to: ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "faster_rcnn_resnet5 100%[===================>] 202.17M  80.5MB/s    in 2.5s    \n",
      "\n",
      "2021-02-10 16:40:50 (80.5 MB/s) - ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’ saved [211996178/211996178]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
    "!tar -xf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6407,
     "status": "ok",
     "timestamp": 1612975252708,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "HKENdH3TfhGb"
   },
   "outputs": [],
   "source": [
    "fine_tune_checkpoint = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6748,
     "status": "ok",
     "timestamp": 1612975253064,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "qzQ84qIQelJB",
    "outputId": "e944aff8-e7eb-4f61-b71a-2d1dcff09d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-10 16:40:53--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3559 (3.5K) [text/plain]\n",
      "Saving to: ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config’\n",
      "\n",
      "\r",
      "          faster_rc   0%[                    ]       0  --.-KB/s               \r",
      "faster_rcnn_resnet5 100%[===================>]   3.48K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-02-10 16:40:53 (61.3 MB/s) - ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config’ saved [3559/3559]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config\n",
    "\n",
    "base_config_path = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1612975317883,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "m3ehVTRgesxS"
   },
   "outputs": [],
   "source": [
    "# edit configuration file (from https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD)\n",
    "\n",
    "import re\n",
    "\n",
    "with open(base_config_path) as f:\n",
    "    config = f.read()\n",
    "\n",
    "with open('model_config.config', 'w') as f:\n",
    "  \n",
    "  # Set labelmap path\n",
    "  config = re.sub('label_map_path: \".*?\"', \n",
    "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
    "  \n",
    "  # Set fine_tune_checkpoint path\n",
    "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
    "  \n",
    "  # Set train tf-record file path\n",
    "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
    "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
    "  \n",
    "  # Set test tf-record file path\n",
    "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
    "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
    "  \n",
    "  # Set number of classes.\n",
    "  config = re.sub('num_classes: [0-9]+',\n",
    "                  'num_classes: {}'.format(num_classes), config)\n",
    "  \n",
    "  # Set batch size\n",
    "  config = re.sub('batch_size: [0-9]+',\n",
    "                  'batch_size: {}'.format(batch_size), config)\n",
    "  \n",
    "  # Set training steps\n",
    "  config = re.sub('num_steps: [0-9]+',\n",
    "                  'num_steps: {}'.format(num_steps), config)\n",
    "  \n",
    "   # Set learning rate base\n",
    "  config = re.sub('learning_rate_base: [0.00000001-9]+',\n",
    "                  'learning_rate_base: {}'.format(learning_rate_base), config)\n",
    "\n",
    "     # Set warmup learning rate\n",
    "  config = re.sub('warmup_learning_rate: [0.00000001-9]+',\n",
    "                  'warmup_learning_rate: {}'.format(warmup_learning_rate), config)\n",
    "\n",
    "  # Set fine-tune checkpoint type to detection\n",
    "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
    "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
    "  \n",
    "  f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1612975325654,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "SmtrS5dihpS_",
    "outputId": "b69f4bb8-eeb8-47b8-ad3d-9081babdf0dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Faster R-CNN with Resnet-50 (v1) with 640x640 input resolution\n",
      "# Trained on COCO, initialized from Imagenet classification checkpoint\n",
      "#\n",
      "# Train on TPU-8\n",
      "#\n",
      "# Achieves 29.3 mAP on COCO17 Val\n",
      "\n",
      "model {\n",
      "  faster_rcnn {\n",
      "    num_classes: 2\n",
      "    image_resizer {\n",
      "      keep_aspect_ratio_resizer {\n",
      "        min_dimension: 640\n",
      "        max_dimension: 640\n",
      "        pad_to_max_dimension: true\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'faster_rcnn_resnet50_keras'\n",
      "      batch_norm_trainable: true\n",
      "    }\n",
      "    first_stage_anchor_generator {\n",
      "      grid_anchor_generator {\n",
      "        scales: [0.25, 0.5, 1.0, 2.0]\n",
      "        aspect_ratios: [0.5, 1.0, 2.0]\n",
      "        height_stride: 16\n",
      "        width_stride: 16\n",
      "      }\n",
      "    }\n",
      "    first_stage_box_predictor_conv_hyperparams {\n",
      "      op: CONV\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 0.0\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        truncated_normal_initializer {\n",
      "          stddev: 0.01\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    first_stage_nms_score_threshold: 0.0\n",
      "    first_stage_nms_iou_threshold: 0.7\n",
      "    first_stage_max_proposals: 300\n",
      "    first_stage_localization_loss_weight: 2.0\n",
      "    first_stage_objectness_loss_weight: 1.0\n",
      "    initial_crop_size: 14\n",
      "    maxpool_kernel_size: 2\n",
      "    maxpool_stride: 2\n",
      "    second_stage_box_predictor {\n",
      "      mask_rcnn_box_predictor {\n",
      "        use_dropout: false\n",
      "        dropout_keep_probability: 1.0\n",
      "        fc_hyperparams {\n",
      "          op: FC\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.0\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            variance_scaling_initializer {\n",
      "              factor: 1.0\n",
      "              uniform: true\n",
      "              mode: FAN_AVG\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        share_box_across_classes: true\n",
      "      }\n",
      "    }\n",
      "    second_stage_post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 0.0\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 300\n",
      "      }\n",
      "      score_converter: SOFTMAX\n",
      "    }\n",
      "    second_stage_localization_loss_weight: 2.0\n",
      "    second_stage_classification_loss_weight: 1.0\n",
      "    use_static_shapes: true\n",
      "    use_matmul_crop_and_resize: true\n",
      "    clip_anchors_to_image: true\n",
      "    use_static_balanced_label_sampler: true\n",
      "    use_matmul_gather_in_matcher: true\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 1\n",
      "  sync_replicas: true\n",
      "  startup_delay_steps: 0\n",
      "  replicas_to_aggregate: 8\n",
      "  num_steps: 25000\n",
      "  optimizer {\n",
      "    momentum_optimizer: {\n",
      "      learning_rate: {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 0.0008\n",
      "          total_steps: 25000\n",
      "          warmup_learning_rate: 1e-05\n",
      "          warmup_steps: 2000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint_version: V2\n",
      "  fine_tune_checkpoint: \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  use_bfloat16: true  # works only on TPUs\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  label_map_path: \"/content/gdrive/MyDrive/imagesV2/label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/gdrive/MyDrive/imagesV2/train.record\"\n",
      "  }\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "  batch_size: 1;\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  label_map_path: \"/content/gdrive/MyDrive/imagesV2/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/gdrive/MyDrive/imagesV2/test.record\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%cat model_config.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1612975337309,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "eRTBSsYthwxG"
   },
   "outputs": [],
   "source": [
    "model_dir = 'training/'\n",
    "pipeline_config_path = 'model_config.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tv0sbQlciKWA"
   },
   "source": [
    "## Train detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2zxx5AXiNNK",
    "outputId": "6690b4fc-4ecb-476f-ba59-27784175a636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-10 16:53:46.954280: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:53:46.954321: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-02-10 16:53:49.356291: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-10 16:53:49.357359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-02-10 16:53:49.391207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-02-10 16:53:49.391829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-02-10 16:53:49.391977: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:53:49.392084: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:53:49.392166: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:53:49.393777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-02-10 16:53:49.394163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-02-10 16:53:49.396188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-02-10 16:53:49.396306: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:53:49.396398: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2021-02-10 16:53:49.396417: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-02-10 16:53:49.396723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-10 16:53:49.396869: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-10 16:53:49.396921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-02-10 16:53:49.396933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0210 16:53:49.397546 140161667147648 cross_device_ops.py:1321] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0210 16:53:49.397767 140161667147648 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 25000\n",
      "I0210 16:53:49.401756 140161667147648 config_util.py:552] Maybe overwriting train_steps: 25000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0210 16:53:49.401916 140161667147648 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0210 16:53:49.464689 140161667147648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/imagesV2/train.record']\n",
      "I0210 16:53:49.471385 140161667147648 dataset_builder.py:163] Reading unweighted datasets: ['/content/gdrive/MyDrive/imagesV2/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/imagesV2/train.record']\n",
      "I0210 16:53:49.471776 140161667147648 dataset_builder.py:80] Reading record datasets for input file: ['/content/gdrive/MyDrive/imagesV2/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0210 16:53:49.471888 140161667147648 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0210 16:53:49.471967 140161667147648 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0210 16:53:49.475540 140161667147648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0210 16:53:49.494984 140161667147648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0210 16:53:55.809569 140161667147648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0210 16:53:58.512639 140161667147648 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-02-10 16:54:01.064183: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-02-10 16:54:01.069902: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "2021-02-10 16:54:11.260135: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 1867 of 2048\n",
      "2021-02-10 16:54:11.561666: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:230] Shuffle buffer filled.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0210 16:54:17.812333 140159127852800 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0210 16:54:24.264960 140159127852800 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0210 16:54:28.413334 140159127852800 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "2021-02-10 16:54:36.521805: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 963379200 exceeds 10% of free system memory.\n",
      "2021-02-10 16:54:36.870820: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 240844800 exceeds 10% of free system memory.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\n",
      "W0210 16:54:39.747792 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._groundtruth_lists\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv\n",
      "W0210 16:54:39.748039 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor\n",
      "W0210 16:54:39.748139 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._maxpool_layer\n",
      "W0210 16:54:39.748214 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._maxpool_layer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor\n",
      "W0210 16:54:39.748280 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n",
      "W0210 16:54:39.748341 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.endpoints\n",
      "W0210 16:54:39.748406 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model.endpoints\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0\n",
      "W0210 16:54:39.748470 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1\n",
      "W0210 16:54:39.748532 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2\n",
      "W0210 16:54:39.748592 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads\n",
      "W0210 16:54:39.748652 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._sorted_head_names\n",
      "W0210 16:54:39.748711 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._sorted_head_names\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets\n",
      "W0210 16:54:39.748771 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head\n",
      "W0210 16:54:39.748832 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head\n",
      "W0210 16:54:39.748898 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._third_stage_heads\n",
      "W0210 16:54:39.748959 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._third_stage_heads\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0._inbound_nodes\n",
      "W0210 16:54:39.749031 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.kernel\n",
      "W0210 16:54:39.749104 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.bias\n",
      "W0210 16:54:39.749165 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1._inbound_nodes\n",
      "W0210 16:54:39.749226 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2._inbound_nodes\n",
      "W0210 16:54:39.749285 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2._inbound_nodes\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings\n",
      "W0210 16:54:39.749344 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background\n",
      "W0210 16:54:39.749404 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets.0\n",
      "W0210 16:54:39.749465 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets.0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers\n",
      "W0210 16:54:39.749525 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers\n",
      "W0210 16:54:39.749584 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0\n",
      "W0210 16:54:39.749716 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0\n",
      "W0210 16:54:39.749784 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.0\n",
      "W0210 16:54:39.749852 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1\n",
      "W0210 16:54:39.749924 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.2\n",
      "W0210 16:54:39.749988 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.0\n",
      "W0210 16:54:39.750053 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1\n",
      "W0210 16:54:39.750128 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.2\n",
      "W0210 16:54:39.750192 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n",
      "W0210 16:54:39.750256 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n",
      "W0210 16:54:39.750321 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.kernel\n",
      "W0210 16:54:39.750387 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.bias\n",
      "W0210 16:54:39.750453 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.kernel\n",
      "W0210 16:54:39.750517 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.bias\n",
      "W0210 16:54:39.750583 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n",
      "W0210 16:54:39.750646 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n",
      "W0210 16:54:39.750719 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n",
      "W0210 16:54:39.750779 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n",
      "W0210 16:54:39.750839 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n",
      "W0210 16:54:39.750905 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n",
      "W0210 16:54:39.750967 140161667147648 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "W0210 16:54:39.751034 140161667147648 util.py:169] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0210 16:54:45.121943 140159127852800 deprecation.py:537] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2021-02-10 16:54:59.144282: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2021-02-10 16:55:03.014181: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2021-02-10 16:55:07.121813: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "INFO:tensorflow:Step 100 per-step time 7.439s loss=1.180\n",
      "I0210 17:07:36.344220 140161667147648 model_lib_v2.py:659] Step 100 per-step time 7.439s loss=1.180\n",
      "INFO:tensorflow:Step 200 per-step time 7.515s loss=0.874\n",
      "I0210 17:20:11.647135 140161667147648 model_lib_v2.py:659] Step 200 per-step time 7.515s loss=0.874\n",
      "INFO:tensorflow:Step 300 per-step time 7.684s loss=0.387\n",
      "I0210 17:32:35.126646 140161667147648 model_lib_v2.py:659] Step 300 per-step time 7.684s loss=0.387\n",
      "INFO:tensorflow:Step 400 per-step time 7.890s loss=0.270\n",
      "I0210 17:45:20.588033 140161667147648 model_lib_v2.py:659] Step 400 per-step time 7.890s loss=0.270\n",
      "INFO:tensorflow:Step 500 per-step time 7.983s loss=0.529\n",
      "I0210 17:58:41.827719 140161667147648 model_lib_v2.py:659] Step 500 per-step time 7.983s loss=0.529\n",
      "INFO:tensorflow:Step 600 per-step time 7.934s loss=0.150\n",
      "I0210 18:12:05.680013 140161667147648 model_lib_v2.py:659] Step 600 per-step time 7.934s loss=0.150\n",
      "INFO:tensorflow:Step 700 per-step time 8.107s loss=0.287\n",
      "I0210 18:25:28.695868 140161667147648 model_lib_v2.py:659] Step 700 per-step time 8.107s loss=0.287\n",
      "INFO:tensorflow:Step 800 per-step time 8.267s loss=0.122\n",
      "I0210 18:38:48.506677 140161667147648 model_lib_v2.py:659] Step 800 per-step time 8.267s loss=0.122\n",
      "INFO:tensorflow:Step 900 per-step time 8.106s loss=0.156\n",
      "I0210 18:52:14.842845 140161667147648 model_lib_v2.py:659] Step 900 per-step time 8.106s loss=0.156\n",
      "INFO:tensorflow:Step 1000 per-step time 8.346s loss=0.843\n",
      "I0210 19:05:38.954356 140161667147648 model_lib_v2.py:659] Step 1000 per-step time 8.346s loss=0.843\n",
      "INFO:tensorflow:Step 1100 per-step time 7.977s loss=2.097\n",
      "I0210 19:19:01.505827 140161667147648 model_lib_v2.py:659] Step 1100 per-step time 7.977s loss=2.097\n",
      "INFO:tensorflow:Step 1200 per-step time 8.023s loss=0.268\n",
      "I0210 19:32:26.767579 140161667147648 model_lib_v2.py:659] Step 1200 per-step time 8.023s loss=0.268\n",
      "INFO:tensorflow:Step 1300 per-step time 7.876s loss=0.269\n",
      "I0210 19:45:48.922428 140161667147648 model_lib_v2.py:659] Step 1300 per-step time 7.876s loss=0.269\n",
      "INFO:tensorflow:Step 1400 per-step time 7.706s loss=1.413\n",
      "I0210 19:58:55.126753 140161667147648 model_lib_v2.py:659] Step 1400 per-step time 7.706s loss=1.413\n",
      "INFO:tensorflow:Step 1500 per-step time 7.844s loss=0.175\n",
      "I0210 20:11:45.516954 140161667147648 model_lib_v2.py:659] Step 1500 per-step time 7.844s loss=0.175\n",
      "INFO:tensorflow:Step 1600 per-step time 7.367s loss=0.144\n",
      "I0210 20:24:22.215885 140161667147648 model_lib_v2.py:659] Step 1600 per-step time 7.367s loss=0.144\n",
      "INFO:tensorflow:Step 1700 per-step time 7.256s loss=0.180\n",
      "I0210 20:36:37.249495 140161667147648 model_lib_v2.py:659] Step 1700 per-step time 7.256s loss=0.180\n",
      "INFO:tensorflow:Step 1800 per-step time 7.541s loss=0.333\n",
      "I0210 20:48:51.262590 140161667147648 model_lib_v2.py:659] Step 1800 per-step time 7.541s loss=0.333\n",
      "INFO:tensorflow:Step 1900 per-step time 7.330s loss=0.433\n",
      "I0210 21:01:20.300524 140161667147648 model_lib_v2.py:659] Step 1900 per-step time 7.330s loss=0.433\n",
      "INFO:tensorflow:Step 2000 per-step time 7.386s loss=0.555\n",
      "I0210 21:13:37.751975 140161667147648 model_lib_v2.py:659] Step 2000 per-step time 7.386s loss=0.555\n",
      "INFO:tensorflow:Step 2100 per-step time 7.573s loss=0.664\n",
      "I0210 21:25:55.438608 140161667147648 model_lib_v2.py:659] Step 2100 per-step time 7.573s loss=0.664\n",
      "INFO:tensorflow:Step 2200 per-step time 7.744s loss=0.944\n",
      "I0210 21:38:56.191589 140161667147648 model_lib_v2.py:659] Step 2200 per-step time 7.744s loss=0.944\n",
      "INFO:tensorflow:Step 2300 per-step time 7.983s loss=0.496\n",
      "I0210 21:52:08.089639 140161667147648 model_lib_v2.py:659] Step 2300 per-step time 7.983s loss=0.496\n",
      "INFO:tensorflow:Step 2400 per-step time 8.200s loss=1.099\n",
      "I0210 22:05:28.895351 140161667147648 model_lib_v2.py:659] Step 2400 per-step time 8.200s loss=1.099\n",
      "INFO:tensorflow:Step 2500 per-step time 7.954s loss=0.401\n",
      "I0210 22:18:57.385951 140161667147648 model_lib_v2.py:659] Step 2500 per-step time 7.954s loss=0.401\n",
      "INFO:tensorflow:Step 2600 per-step time 7.912s loss=0.439\n",
      "I0210 22:32:22.863504 140161667147648 model_lib_v2.py:659] Step 2600 per-step time 7.912s loss=0.439\n",
      "INFO:tensorflow:Step 2700 per-step time 7.657s loss=0.399\n",
      "I0210 22:45:19.444773 140161667147648 model_lib_v2.py:659] Step 2700 per-step time 7.657s loss=0.399\n",
      "INFO:tensorflow:Step 2800 per-step time 7.596s loss=1.320\n",
      "I0210 22:58:08.691925 140161667147648 model_lib_v2.py:659] Step 2800 per-step time 7.596s loss=1.320\n",
      "INFO:tensorflow:Step 2900 per-step time 7.649s loss=0.874\n",
      "I0210 23:10:59.767261 140161667147648 model_lib_v2.py:659] Step 2900 per-step time 7.649s loss=0.874\n",
      "INFO:tensorflow:Step 3000 per-step time 7.562s loss=0.665\n",
      "I0210 23:23:30.558638 140161667147648 model_lib_v2.py:659] Step 3000 per-step time 7.562s loss=0.665\n",
      "INFO:tensorflow:Step 3100 per-step time 7.560s loss=0.551\n",
      "I0210 23:36:08.353561 140161667147648 model_lib_v2.py:659] Step 3100 per-step time 7.560s loss=0.551\n",
      "INFO:tensorflow:Step 3200 per-step time 7.402s loss=0.871\n",
      "I0210 23:48:28.531411 140161667147648 model_lib_v2.py:659] Step 3200 per-step time 7.402s loss=0.871\n",
      "INFO:tensorflow:Step 3300 per-step time 7.328s loss=0.963\n",
      "I0211 00:00:41.510436 140161667147648 model_lib_v2.py:659] Step 3300 per-step time 7.328s loss=0.963\n",
      "INFO:tensorflow:Step 3400 per-step time 7.320s loss=1.221\n",
      "I0211 00:12:57.049269 140161667147648 model_lib_v2.py:659] Step 3400 per-step time 7.320s loss=1.221\n",
      "INFO:tensorflow:Step 3500 per-step time 7.472s loss=0.980\n",
      "I0211 00:25:15.725571 140161667147648 model_lib_v2.py:659] Step 3500 per-step time 7.472s loss=0.980\n",
      "INFO:tensorflow:Step 3600 per-step time 7.474s loss=0.561\n",
      "I0211 00:37:35.156487 140161667147648 model_lib_v2.py:659] Step 3600 per-step time 7.474s loss=0.561\n",
      "INFO:tensorflow:Step 3700 per-step time 7.341s loss=1.593\n",
      "I0211 00:49:44.647980 140161667147648 model_lib_v2.py:659] Step 3700 per-step time 7.341s loss=1.593\n",
      "INFO:tensorflow:Step 3800 per-step time 7.384s loss=0.270\n",
      "I0211 01:01:59.881721 140161667147648 model_lib_v2.py:659] Step 3800 per-step time 7.384s loss=0.270\n",
      "INFO:tensorflow:Step 3900 per-step time 7.310s loss=0.877\n",
      "I0211 01:14:12.999150 140161667147648 model_lib_v2.py:659] Step 3900 per-step time 7.310s loss=0.877\n",
      "INFO:tensorflow:Step 4000 per-step time 7.193s loss=1.062\n",
      "I0211 01:26:22.184267 140161667147648 model_lib_v2.py:659] Step 4000 per-step time 7.193s loss=1.062\n",
      "INFO:tensorflow:Step 4100 per-step time 7.399s loss=0.268\n",
      "I0211 01:38:35.619868 140161667147648 model_lib_v2.py:659] Step 4100 per-step time 7.399s loss=0.268\n",
      "INFO:tensorflow:Step 4200 per-step time 7.538s loss=1.148\n",
      "I0211 01:50:55.720817 140161667147648 model_lib_v2.py:659] Step 4200 per-step time 7.538s loss=1.148\n",
      "INFO:tensorflow:Step 4300 per-step time 7.507s loss=0.730\n",
      "I0211 02:03:20.470879 140161667147648 model_lib_v2.py:659] Step 4300 per-step time 7.507s loss=0.730\n",
      "INFO:tensorflow:Step 4400 per-step time 7.568s loss=0.212\n",
      "I0211 02:15:49.461987 140161667147648 model_lib_v2.py:659] Step 4400 per-step time 7.568s loss=0.212\n",
      "INFO:tensorflow:Step 4500 per-step time 7.418s loss=0.273\n",
      "I0211 02:28:16.047657 140161667147648 model_lib_v2.py:659] Step 4500 per-step time 7.418s loss=0.273\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_config_path} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PK8amcT_wgVb"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/content/training/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3GNLS4ywstA"
   },
   "source": [
    "## Export model inference graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rYr6VKH8_QU"
   },
   "source": [
    "The below code cell adds a line to the tf_utils.py file. This is a temporary fix to a [exporting issue](https://github.com/tensorflow/models/issues/8841) occuring when using the OD API with Tensorflow 2. This code will be removed as soon as the OD Team puts out a fix.\n",
    "\n",
    "All credit goes to Github user [Jacobsolawetz](https://github.com/Jacobsolawetz), who provided this [temporary fix](https://github.com/tensorflow/models/issues/8841#issuecomment-657647648)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Usv5FMT1xG1L"
   },
   "outputs": [],
   "source": [
    "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py') as f:\n",
    "    tf_utils = f.read()\n",
    "\n",
    "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py', 'w') as f:\n",
    "  # Set labelmap path\n",
    "  throw_statement = \"raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\"\n",
    "  tf_utils = tf_utils.replace(throw_statement, \"if not isinstance(x, str):\" + throw_statement)\n",
    "  f.write(tf_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcvbNjcZw2er"
   },
   "outputs": [],
   "source": [
    "output_directory = 'inference_graph'\n",
    "\n",
    "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir {model_dir} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_config_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "error",
     "timestamp": 1613035591349,
     "user": {
      "displayName": "Nick Jacobs",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimI6AM1TtEknGddnNXEGRtG2Tex6NkYRTkwz2WsQ=s64",
      "userId": "18144754034929678398"
     },
     "user_tz": -60
    },
    "id": "LcWVXuGAxeZ4",
    "outputId": "77cc91a6-a1fa-4744-da49-10956c0a2c44"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fd61bd2a0106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/{output_directory}/saved_model/saved_model.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output_directory' is not defined"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(f'/content/{output_directory}/saved_model/saved_model.pb') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kopie van Tensorflow 2 Object Detection: Train model.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb",
     "timestamp": 1612777869968
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
